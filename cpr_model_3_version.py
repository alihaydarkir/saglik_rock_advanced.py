# ğŸš€ QUERY CHUNKING + UI FIX - CPR Professional System v2.1
# Bu kodu cpr_chunking_enhanced.py olarak kaydet

import streamlit as st
import json
import numpy as np
import random
import time
import uuid
from typing import List, Dict, Tuple
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import re

try:
    import chromadb
    from chromadb.config import Settings
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False

try:
    from sentence_transformers import SentenceTransformer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

class QueryChunker:
    """AkÄ±llÄ± sorgu parÃ§alama sistemi"""
    
    def __init__(self):
        # Chunking kurallarÄ±
        self.ayirici_kelimeler = [
            've', 'ile', 'ayrÄ±ca', 'hem', 'ek olarak', 'bunun yanÄ±nda',
            'and', 'with', 'also', 'plus', 'additionally'
        ]
        
        self.soru_kelimeleri = [
            'nasÄ±l', 'nedir', 'neden', 'ne zaman', 'nerede', 'kaÃ§', 'hangi',
            'how', 'what', 'why', 'when', 'where', 'which', 'how many'
        ]
        
        self.cpr_ana_konular = [
            'cpr', 'kompresyon', 'solunum', 'aed', 'defibrilasyon',
            'epinefrin', 'amiodarone', 'atropin', 'hipotermik',
            'yetiÅŸkin', 'Ã§ocuk', 'bebek', 'kalp', 'nabÄ±z'
        ]
    
    def akilli_chunking(self, sorgu: str) -> List[str]:
        """AkÄ±llÄ± sorgu parÃ§alama"""
        if len(sorgu.split()) <= 8:
            return [sorgu]  # KÄ±sa sorular iÃ§in chunking yapma
        
        print(f"[CHUNKING] Uzun sorgu tespit edildi: '{sorgu[:50]}...'")
        
        chunks = []
        
        # 1. VirgÃ¼l ve nokta ile bÃ¶l
        ana_parcalar = re.split(r'[,.]', sorgu)
        
        # 2. Her ana parÃ§ayÄ± iÅŸle
        for parca in ana_parcalar:
            parca = parca.strip()
            if not parca:
                continue
                
            # 3. AyÄ±rÄ±cÄ± kelimelerle bÃ¶l
            for ayirici in self.ayirici_kelimeler:
                if ayirici in parca.lower():
                    alt_parcalar = parca.split(ayirici)
                    for alt_parca in alt_parcalar:
                        alt_parca = alt_parca.strip()
                        if len(alt_parca.split()) >= 3:  # Minimum 3 kelime
                            chunks.append(alt_parca)
                    break
            else:
                # AyÄ±rÄ±cÄ± yoksa direkt ekle
                if len(parca.split()) >= 3:
                    chunks.append(parca)
        
        # 4. Soru kelimesi olan parÃ§alarÄ± Ã¶nceliklendir
        soru_chunks = []
        normal_chunks = []
        
        for chunk in chunks:
            if any(soru in chunk.lower() for soru in self.soru_kelimeleri):
                soru_chunks.append(chunk)
            else:
                normal_chunks.append(chunk)
        
        # 5. CPR kelimesi ekle (eÄŸer yoksa)
        enhanced_chunks = []
        for chunk in soru_chunks + normal_chunks:
            if not any(cpr_kelime in chunk.lower() for cpr_kelime in self.cpr_ana_konular):
                # CPR konteksti ekle
                chunk = f"CPR {chunk}"
            enhanced_chunks.append(chunk)
        
        # 6. Orijinal sorguyu da ekle (son ÅŸans)
        enhanced_chunks.append(sorgu)
        
        print(f"[CHUNKING] {len(enhanced_chunks)} chunk oluÅŸturuldu:")
        for i, chunk in enumerate(enhanced_chunks):
            print(f"  Chunk {i+1}: '{chunk[:40]}...'")
        
        return enhanced_chunks[:5]  # Maksimum 5 chunk

class EnhancedRetriever:
    """Query Chunking ile geliÅŸtirilmiÅŸ retriever"""
    
    def __init__(self):
        self.koleksiyon_adi = "cpr_chunking_v1"
        self.chroma_client = None
        self.koleksiyon = None
        self.model = None
        self.chunker = QueryChunker()
        self.performans_gecmisi = []
        
        # GeliÅŸmiÅŸ kelime haritasÄ± (Ã¶ncekinden daha kapsamlÄ±)
        self.mega_kelime_haritasi = {
            # Ä°laÃ§ terimleri
            'epinefrin': ['epinephrine', 'adrenaline', 'adrenalin', 'vazopresor', 'vazopressÃ¶r', 'noradrenalin'],
            'amiodarone': ['amiodaron', 'antiaritmik', 'kardiak ilaÃ§', 'ritim dÃ¼zenleyici', 'kordarone'],
            'atropin': ['atropine', 'antikolinerjik', 'bradikardi ilacÄ±', 'atropine sulfat'],
            'lidokain': ['lidocaine', 'lokal anestezik', 'antiaritmik', 'xylocaine'],
            'magnezyum': ['magnesium', 'mg', 'elektrolit', 'magnesium sulfat'],
            
            # CPR terimleri - KAPSAMLI
            'cpr': ['cardiopulmonary resuscitation', 'kalp masajÄ±', 'canlandÄ±rma', 'resÃ¼sitasyon', 
                   'yaÅŸam desteÄŸi', 'temel yaÅŸam desteÄŸi', 'ileri yaÅŸam desteÄŸi', 'kardiyopulmoner',
                   'kalp akciÄŸer canlandÄ±rma', 'temel canlandÄ±rma'],
            'kompresyon': ['compression', 'basÄ±nÃ§', 'gÃ¶ÄŸÃ¼s basÄ±sÄ±', 'masaj', 'basma', 'gÃ¶ÄŸÃ¼s kompresyonu'],
            'ventilasyon': ['solunum', 'nefes', 'hava verme', 'breathing', 'oksijen', 'yapay solunum',
                           'mouth to mouth', 'aÄŸÄ±zdan aÄŸÄ±za', 'bag mask'],
            'defibrilasyon': ['defibrillation', 'ÅŸok', 'elektrik ÅŸoku', 'kardiyoversiyon', 'DC ÅŸok'],
            
            # Cihaz terimleri  
            'aed': ['automated external defibrillator', 'defibrillatÃ¶r', 'ÅŸok cihazÄ±', 'otomatik defibrillatÃ¶r',
                   'external defibrillator', 'aed cihazÄ±'],
            'monitÃ¶r': ['monitor', 'ekg', 'ecg', 'kalp ritmi takibi', 'cardiac monitor'],
            
            # Anatomi terimleri - GENÄ°Å
            'kalp': ['heart', 'kardiak', 'miyokard', 'ventrikÃ¼l', 'atriyum', 'cardiac', 'jantung'],
            'gÃ¶ÄŸÃ¼s': ['chest', 'toraks', 'gÃ¶ÄŸÃ¼s kafesi', 'sternum', 'thorax'],
            'nabÄ±z': ['pulse', 'kalp ritmi', 'heartbeat', 'nabÄ±z hÄ±zÄ±', 'heart rate'],
            
            # YaÅŸ gruplarÄ± - DETAYLI
            'yetiÅŸkin': ['adult', 'eriÅŸkin', 'bÃ¼yÃ¼k', '18 yaÅŸ Ã¼zeri', 'mature', 'grown up'],
            'Ã§ocuk': ['child', 'pediatrik', 'kÃ¼Ã§Ã¼k', '1-8 yaÅŸ', 'okul Ã§aÄŸÄ±', 'pediatric', 'kid'],
            'bebek': ['infant', 'baby', 'yenidoÄŸan', '0-12 ay', 'sÃ¼t Ã§ocuÄŸu', 'newborn'],
            
            # Ã–lÃ§Ã¼ birimleri - KAPSAMLI
            'doz': ['dose', 'miktar', 'amount', 'dozaj', 'dosis', 'quantity'],
            'mg': ['milligram', 'miligram', 'ml', 'cc', 'mcg', 'microgram'],
            'oran': ['ratio', 'rate', 'frequency', 'hÄ±z', 'frekans', 'proportion'],
            'derinlik': ['depth', 'derinlik', 'cm', 'santimetre', 'centimeter'],
            
            # Acil durum terimleri - GENÄ°Å
            'arrest': ['kalp durmasÄ±', 'kardiyak arrest', 'cardiac arrest', 'ani Ã¶lÃ¼m', 'sudden death'],
            'hipotermik': ['hypothermic', 'soÄŸuk', 'dÃ¼ÅŸÃ¼k sÄ±caklÄ±k', 'hipotermi', 'hypothermia'],
            'vf': ['ventricular fibrillation', 'ventrikÃ¼l fibrilasyonu', 'v-fib'],
            'vt': ['ventricular tachycardia', 'ventrikÃ¼l taÅŸikardisi', 'v-tach'],
            'asistol': ['asystole', 'dÃ¼z Ã§izgi', 'kalp durmasÄ±', 'flatline'],
            
            # Soru kelimeleri - KAPSAMLI
            'nasÄ±l': ['how', 'ne ÅŸekilde', 'hangi yÃ¶ntem', 'prosedÃ¼r', 'adÄ±mlar'],
            'nedir': ['what', 'ne', 'tanÄ±m', 'definition'],
            'kaÃ§': ['how much', 'how many', 'ne kadar', 'miktar', 'quantity'],
            'nerede': ['where', 'hangi bÃ¶lge', 'lokasyon', 'location'],
            'ne zaman': ['when', 'hangi durumda', 'zamanÄ±', 'timing'],
            
            # Yeni eklenen - Ã–ZEL DURUMLAR
            'adÄ±m': ['step', 'adÄ±mlar', 'procedure', 'protocol', 'stages'],
            'dikkat': ['attention', 'care', 'caution', 'warning', 'notice'],
            'risk': ['risk', 'danger', 'hazard', 'complication', 'side effect'],
            'enfeksiyon': ['infection', 'contamination', 'disease', 'pathogen']
        }
    
    def sistem_baslat(self):
        """GeliÅŸmiÅŸ sistem baÅŸlatma"""
        if not CHROMA_AVAILABLE or not TRANSFORMERS_AVAILABLE:
            st.error("âŒ pip install chromadb sentence-transformers plotly")
            return False
        
        try:
            with st.spinner("ğŸš€ Query Chunking sistemi baÅŸlatÄ±lÄ±yor..."):
                # ChromaDB
                self.chroma_client = chromadb.Client(Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                ))
                
                # GÃ¼Ã§lÃ¼ model
                st.info("ğŸ“¥ GÃ¼Ã§lÃ¼ TÃ¼rkÃ§e modeli yÃ¼kleniyor...")
                self.model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased')
                
                try:
                    self.koleksiyon = self.chroma_client.get_collection(self.koleksiyon_adi)
                    st.success(f"âœ… Chunking database hazÄ±r: {self.koleksiyon.count()} dokÃ¼man")
                except:
                    self.koleksiyon = self.chroma_client.create_collection(
                        name=self.koleksiyon_adi,
                        metadata={"version": "chunking_v1", "model": "distiluse-multilingual"}
                    )
                    st.info("ğŸ†• Yeni chunking database oluÅŸturuluyor...")
                
            return True
            
        except Exception as e:
            st.error(f"âŒ Sistem hatasÄ±: {str(e)}")
            return False
    
    def _mega_kelime_genisletme(self, metin: str) -> str:
        """Mega kelime geniÅŸletme sistemi"""
        genisletilmis = metin.lower()
        
        # Her kelime iÃ§in kapsamlÄ± eÅŸleÅŸtirme
        for anahtar, esanlamlilar in self.mega_kelime_haritasi.items():
            # Ana kelime varsa eÅŸanlamlÄ±larÄ± ekle
            if anahtar in genisletilmis:
                genisletilmis += " " + " ".join(esanlamlilar)
            
            # EÅŸanlamlÄ±lardan biri varsa ana kelimeyi ekle
            for esanlamli in esanlamlilar:
                if esanlamli.lower() in genisletilmis.lower() and anahtar not in genisletilmis:
                    genisletilmis += " " + anahtar
        
        # Ã–zel durum iÅŸlemleri - GENÄ°Å
        if any(kelime in genisletilmis for kelime in ["kaÃ§", "ne kadar", "miktar"]):
            genisletilmis += " doz miktar mg amount dose quantity"
        
        if any(kelime in genisletilmis for kelime in ["nasÄ±l", "adÄ±m", "prosedÃ¼r"]):
            genisletilmis += " prosedÃ¼r adÄ±m yÃ¶ntem protokol procedure steps"
            
        if any(kelime in genisletilmis for kelime in ["dikkat", "risk", "Ã¶nlem"]):
            genisletilmis += " dikkat edilmesi gereken risk Ã¶nlem caution warning"
            
        return genisletilmis
    
    def dokumanlar_ekle(self, dokumanlar: List[Dict], temizle: bool = False):
        """GeliÅŸmiÅŸ dokÃ¼man ekleme"""
        if not self.koleksiyon or not self.model:
            return False
        
        if temizle:
            try:
                self.chroma_client.delete_collection(self.koleksiyon_adi)
            except:
                pass
            self.koleksiyon = self.chroma_client.create_collection(
                name=self.koleksiyon_adi,
                metadata={"version": "chunking_v1", "model": "distiluse-multilingual"}
            )
        
        progress = st.progress(0)
        status = st.empty()
        time_start = time.time()
        
        ids, embeddings, metadatas, documents = [], [], [], []
        
        for i, dok in enumerate(dokumanlar):
            ids.append(dok.get('id', str(uuid.uuid4())))
            
            # MEGA geniÅŸletilmiÅŸ iÃ§erik
            temel_icerik = dok['icerik']
            kategori = dok.get('kategori', '')
            alt_kategori = dok.get('alt_kategori', '')
            
            # Tam kapsamlÄ± geniÅŸletme
            tam_icerik = f"{temel_icerik} {kategori} {alt_kategori}"
            genisletilmis_icerik = self._mega_kelime_genisletme(tam_icerik)
            
            # GÃ¼Ã§lÃ¼ embedding
            embedding = self.model.encode(genisletilmis_icerik).tolist()
            embeddings.append(embedding)
            
            # Zengin metadata
            metadatas.append({
                'kategori': kategori,
                'alt_kategori': alt_kategori,
                'guvenilirlik': float(dok.get('guvenilirlik', 0.8)),
                'acillik_seviyesi': dok.get('acillik_seviyesi', 'normal'),
                'kaynak': dok.get('metadata', {}).get('kaynak', 'AHA Guidelines'),
                'protokol_tipi': dok.get('metadata', {}).get('protokol_tipi', 'standart'),
                'ekleme_tarihi': datetime.now().isoformat(),
                'kelime_sayisi': len(temel_icerik.split()),
                'chunking_ready': True
            })
            
            documents.append(temel_icerik)
            
            # Progress
            elapsed = time.time() - time_start
            if i > 0:
                eta = (elapsed / i) * (len(dokumanlar) - i)
                status.text(f"ğŸ“Š Chunking hazÄ±rlÄ±k: {i + 1}/{len(dokumanlar)} â€¢ ETA: {eta:.1f}s")
            
            progress.progress((i + 1) / len(dokumanlar))
        
        try:
            self.koleksiyon.add(
                embeddings=embeddings,
                metadatas=metadatas,
                documents=documents,
                ids=ids
            )
            
            total_time = time.time() - time_start
            progress.progress(1.0)
            status.success(f"âœ… {len(dokumanlar)} chunking-ready dokÃ¼man eklendi! ({total_time:.1f}s)")
            time.sleep(1.5)
            progress.empty()
            status.empty()
            return True
            
        except Exception as e:
            st.error(f"âŒ Ekleme hatasÄ±: {str(e)}")
            return False
    
    def chunked_arama(self, sorgu: str, top_k: int = 10) -> List[Dict]:
        """ğŸš€ QUERY CHUNKING ile geliÅŸmiÅŸ arama"""
        if not self.koleksiyon or not self.model:
            return []
        
        try:
            # 1. SORGUYU CHUNKLA
            chunks = self.chunker.akilli_chunking(sorgu)
            
            print(f"[CHUNKED SEARCH] '{sorgu[:30]}...' iÃ§in {len(chunks)} chunk ile arama")
            
            # 2. HER CHUNK Ä°Ã‡Ä°N ARAMA YAP
            tum_sonuclar = {}  # ID bazÄ±nda sonuÃ§larÄ± topla
            chunk_skorlari = {}  # Her chunk iÃ§in ayrÄ± skorlar
            
            for chunk_idx, chunk in enumerate(chunks):
                # Chunk'Ä± geniÅŸlet
                genisletilmis_chunk = self._mega_kelime_genisletme(chunk)
                
                # Chunk embedding
                chunk_embedding = self.model.encode(genisletilmis_chunk).tolist()
                
                # Arama yap
                chunk_sonuclar = self.koleksiyon.query(
                    query_embeddings=[chunk_embedding],
                    n_results=top_k,
                    include=["documents", "metadatas", "distances"]
                )
                
                # SonuÃ§larÄ± iÅŸle
                if chunk_sonuclar['documents'] and len(chunk_sonuclar['documents'][0]) > 0:
                    for i in range(len(chunk_sonuclar['documents'][0])):
                        doc_id = chunk_sonuclar['ids'][0][i]
                        distance = chunk_sonuclar['distances'][0][i]
                        similarity = max(0.0, 1.0 - distance)
                        
                        # Chunk aÄŸÄ±rlÄ±ÄŸÄ± (ilk chunk'lar daha Ã¶nemli)
                        chunk_weight = 1.0 - (chunk_idx * 0.1)
                        weighted_score = similarity * chunk_weight
                        
                        if doc_id not in tum_sonuclar:
                            tum_sonuclar[doc_id] = {
                                'id': doc_id,
                                'icerik': chunk_sonuclar['documents'][0][i],
                                'metadata': chunk_sonuclar['metadatas'][0][i],
                                'chunk_skorlari': [],
                                'max_skor': 0,
                                'ortalama_skor': 0,
                                'chunk_sayisi': 0
                            }
                        
                        # Chunk skorlarÄ±nÄ± topla
                        tum_sonuclar[doc_id]['chunk_skorlari'].append({
                            'chunk_idx': chunk_idx,
                            'chunk_text': chunk[:30] + '...',
                            'similarity': similarity,
                            'weighted_score': weighted_score
                        })
                        
                        # Max ve ortalama hesapla
                        skorlar = [cs['weighted_score'] for cs in tum_sonuclar[doc_id]['chunk_skorlari']]
                        tum_sonuclar[doc_id]['max_skor'] = max(skorlar)
                        tum_sonuclar[doc_id]['ortalama_skor'] = sum(skorlar) / len(skorlar)
                        tum_sonuclar[doc_id]['chunk_sayisi'] = len(skorlar)
            
            # 3. SONUÃ‡LARI BÄ°RLEÅTÄ°R VE SKORLA
            final_sonuclar = []
            for doc_id, data in tum_sonuclar.items():
                # CHUNKING BONUSU: Birden fazla chunk'ta bulunan dokÃ¼manlar bonus alÄ±r
                multi_chunk_bonus = 1.0 + (data['chunk_sayisi'] - 1) * 0.15
                
                # GÃ¼venilirlik bonusu
                guvenilirlik = data['metadata'].get('guvenilirlik', 0.8)
                acillik = data['metadata'].get('acillik_seviyesi', 'normal')
                acillik_bonus = 1.2 if acillik == 'kritik' else 1.0
                
                # FINAL SKOR = (Max + Ortalama) / 2 * Bonuslar
                final_score = ((data['max_skor'] + data['ortalama_skor']) / 2) * multi_chunk_bonus * (0.7 + 0.3 * guvenilirlik) * acillik_bonus
                
                final_sonuclar.append({
                    'id': doc_id,
                    'icerik': data['icerik'],
                    'benzerlik_skoru': final_score,
                    'ham_max_skor': data['max_skor'],
                    'ham_ortalama_skor': data['ortalama_skor'],
                    'chunk_sayisi': data['chunk_sayisi'],
                    'chunk_detaylari': data['chunk_skorlari'],
                    'metadata': data['metadata'],
                    'kategori': data['metadata'].get('kategori', 'genel'),
                    'guvenilirlik': guvenilirlik,
                    'acillik': acillik,
                    'multi_chunk_bonus': multi_chunk_bonus
                })
            
            # 4. SKORLARA GÃ–RE SIRALA
            final_sonuclar.sort(key=lambda x: x['benzerlik_skoru'], reverse=True)
            
            # 5. PERFORMANS KAYDI
            if final_sonuclar:
                self.performans_gecmisi.append({
                    'timestamp': datetime.now(),
                    'sorgu': sorgu,
                    'chunk_sayisi': len(chunks),
                    'en_iyi_skor': final_sonuclar[0]['benzerlik_skoru'],
                    'sonuc_sayisi': len(final_sonuclar),
                    'chunking_bonus_kullanildi': True
                })
                
                if len(self.performans_gecmisi) > 20:
                    self.performans_gecmisi.pop(0)
            
            # 6. DEBUG BÄ°LGÄ°SÄ°
            print(f"[CHUNKED RESULTS] '{sorgu[:30]}...' iÃ§in {len(final_sonuclar)} birleÅŸtirilmiÅŸ sonuÃ§:")
            for i, sonuc in enumerate(final_sonuclar[:3]):
                print(f"  {i+1}. Final: {sonuc['benzerlik_skoru']:.3f}, Max: {sonuc['ham_max_skor']:.3f}, "
                      f"Chunks: {sonuc['chunk_sayisi']}, Kategori: {sonuc['kategori']}")
            
            return final_sonuclar
            
        except Exception as e:
            st.error(f"âŒ Chunked arama hatasÄ±: {str(e)}")
            return []
    
    def get_performans_grafigi(self):
        """Chunking performans grafik verisi"""
        if not self.performans_gecmisi:
            return None
        
        return {
            'timestamps': [p['timestamp'] for p in self.performans_gecmisi],
            'skorlar': [p['en_iyi_skor'] for p in self.performans_gecmisi],
            'chunk_sayilari': [p['chunk_sayisi'] for p in self.performans_gecmisi],
            'sorgular': [p['sorgu'][:15] + '...' if len(p['sorgu']) > 15 else p['sorgu'] 
                        for p in self.performans_gecmisi]
        }

class ChunkingCPRSistemi:
    """Query Chunking ile geliÅŸtirilmiÅŸ CPR sistemi"""
    
    def __init__(self):
        self.retriever = EnhancedRetriever()
        self.bilgi_bankasi = []
        self.toplam_sorgu = 0
        self.basarili_sorgu = 0
        self.chunking_kullanim_sayisi = 0
        self.sistem_baslatma_zamani = None
        
        # Performans metrikleri
        self.ortalama_yanit_suresi = []
        self.kategori_dagilimi = {}
        self.chunk_istatistikleri = {
            'toplam_chunk': 0,
            'basarili_chunk': 0,
            'ortalama_chunk_per_sorgu': 0
        }
    
    def sistem_baslat(self):
        """Chunking sistemi baÅŸlatma"""
        self.sistem_baslatma_zamani = datetime.now()
        
        try:
            if not self.retriever.sistem_baslat():
                return False
            
            # JSON veri yÃ¼kleme
            try:
                with open('cpr_egitim_bilgi_bankasi.json', 'r', encoding='utf-8') as f:
                    self.bilgi_bankasi = json.load(f)
                    
                # Kategori analizi
                for dok in self.bilgi_bankasi:
                    kategori = dok.get('kategori', 'genel')
                    self.kategori_dagilimi[kategori] = self.kategori_dagilimi.get(kategori, 0) + 1
                    
            except FileNotFoundError:
                st.error("âŒ cpr_egitim_bilgi_bankasi.json bulunamadÄ±!")
                return False
            
            # Database yÃ¼kleme
            if self.retriever.koleksiyon.count() == 0:
                st.info("ğŸ”„ Chunking database oluÅŸturuluyor...")
                if not self.retriever.dokumanlar_ekle(self.bilgi_bankasi, temizle=True):
                    return False
            
            return True
            
        except Exception as e:
            st.error(f"âŒ Sistem hatasÄ±: {str(e)}")
            return False
    
    def chunking_sorgulama(self, soru: str) -> Dict:
        """ğŸš€ CHUNKING ile geliÅŸmiÅŸ sorgulama"""
        start_time = time.time()
        self.toplam_sorgu += 1
        
        # Chunking kullanÄ±m kararÄ±
        kelime_sayisi = len(soru.split())
        chunking_kullan = kelime_sayisi > 8
        
        if chunking_kullan:
            self.chunking_kullanim_sayisi += 1
            print(f"[CHUNKING ACTIVE] {kelime_sayisi} kelimelik sorgu iÃ§in chunking aktif")
            
            # Chunked arama
            sonuclar = self.retriever.chunked_arama(soru, top_k=8)
        else:
            print(f"[NORMAL SEARCH] {kelime_sayisi} kelimelik sorgu iÃ§in normal arama")
            # Normal arama (chunking olmadan)
            genisletilmis_sorgu = self.retriever._mega_kelime_genisletme(soru)
            sorgu_embedding = self.retriever.model.encode(genisletilmis_sorgu).tolist()
            
            normal_sonuclar = self.retriever.koleksiyon.query(
                query_embeddings=[sorgu_embedding],
                n_results=8,
                include=["documents", "metadatas", "distances"]
            )
            
            # Normal sonuÃ§larÄ± formatla
            sonuclar = []
            if normal_sonuclar['documents'] and len(normal_sonuclar['documents'][0]) > 0:
                for i in range(len(normal_sonuclar['documents'][0])):
                    distance = normal_sonuclar['distances'][0][i]
                    similarity = max(0.0, 1.0 - distance)
                    
                    sonuclar.append({
                        'id': normal_sonuclar['ids'][0][i],
                        'icerik': normal_sonuclar['documents'][0][i],
                        'benzerlik_skoru': similarity,
                        'ham_max_skor': similarity,
                        'ham_ortalama_skor': similarity,
                        'chunk_sayisi': 1,
                        'metadata': normal_sonuclar['metadatas'][0][i],
                        'kategori': normal_sonuclar['metadatas'][0][i].get('kategori', 'genel'),
                        'guvenilirlik': normal_sonuclar['metadatas'][0][i].get('guvenilirlik', 0.8)
                    })
        
        # Intelligent eÅŸik sistemi (chunking'e gÃ¶re ayarlanmÄ±ÅŸ)
        esik_kurallari = {
            'doz_miktar': (['doz', 'miktar', 'mg', 'kaÃ§', 'ne kadar'], 0.03 if chunking_kullan else 0.05),
            'acil_kritik': (['acil', 'kritik', 'emergency', 'arrest', 'durma'], 0.02 if chunking_kullan else 0.04),
            'prosedur': (['nasÄ±l', 'how', 'adÄ±m', 'yÃ¶ntem', 'prosedÃ¼r'], 0.04 if chunking_kullan else 0.06),
            'tanÄ±m': (['nedir', 'what', 'tanÄ±m', 'ne'], 0.06 if chunking_kullan else 0.08),
            'genel': ([], 0.08 if chunking_kullan else 0.12)
        }
        
        # Uygun eÅŸiÄŸi bul
        kullanilan_esik = esik_kurallari['genel'][1]
        esik_tipi = 'genel'
        
        for tip, (kelimeler, esik_degeri) in esik_kurallari.items():
            if any(kelime in soru.lower() for kelime in kelimeler):
                kullanilan_esik = esik_degeri
                esik_tipi = tip
                break
        
        kaliteli_sonuclar = [s for s in sonuclar if s['benzerlik_skoru'] > kullanilan_esik]
        
        # CPR ve acil durum analizi
        cpr_kelimeler = ['cpr', 'kalp', 'resÃ¼sitasyon', 'defibrilasyon', 'epinefrin', 'aed', 'kompresyon']
        cpr_odakli = any(kelime in soru.lower() for kelime in cpr_kelimeler)
        
        acil_kelimeler = ['acil', 'kritik', 'emergency', 'arrest', 'durma', 'kriz']
        acil_durum = any(kelime in soru.lower() for kelime in acil_kelimeler)
        
        # YanÄ±t oluÅŸturma
        if len(kaliteli_sonuclar) >= 1:
            self.basarili_sorgu += 1
            yanit = self._chunking_yanit_olustur(soru, kaliteli_sonuclar[:3], acil_durum, chunking_kullan)
            basarili = True
        else:
            yanit = self._chunking_oneri_sistemi(soru, sonuclar[:2], chunking_kullan)
            basarili = False
        
        # Performans hesaplama
        yanit_suresi = time.time() - start_time
        self.ortalama_yanit_suresi.append(yanit_suresi)
        
        if len(self.ortalama_yanit_suresi) > 10:
            self.ortalama_yanit_suresi.pop(0)
        
        # Chunk istatistikleri gÃ¼ncelle
        if chunking_kullan and kaliteli_sonuclar:
            self.chunk_istatistikleri['toplam_chunk'] += sum(s.get('chunk_sayisi', 1) for s in kaliteli_sonuclar[:3])
            self.chunk_istatistikleri['basarili_chunk'] += len(kaliteli_sonuclar)
            self.chunk_istatistikleri['ortalama_chunk_per_sorgu'] = self.chunk_istatistikleri['toplam_chunk'] / max(1, self.chunking_kullanim_sayisi)
        
        # Skor deÄŸerlendirmesi
        if kaliteli_sonuclar:
            en_iyi_skor = kaliteli_sonuclar[0]['benzerlik_skoru']
            if en_iyi_skor > 0.8:
                performans = "ğŸ† MÃ¼kemmel"
            elif en_iyi_skor > 0.6:
                performans = "ğŸš€ Ã‡ok Ä°yi"
            elif en_iyi_skor > 0.4:
                performans = "ğŸ“ˆ Ä°yi"
            elif en_iyi_skor > 0.2:
                performans = "ğŸ“Š Orta"
            else:
                performans = "ğŸ“‰ DÃ¼ÅŸÃ¼k"
        else:
            en_iyi_skor = 0
            performans = "âš ï¸ Yetersiz"
        
        return {
            "basarili": basarili,
            "yanit": yanit,
            "bulunan_dokuman_sayisi": len(sonuclar),
            "kaliteli_sonuc_sayisi": len(kaliteli_sonuclar),
            "en_iyi_skor": en_iyi_skor,
            "sistem_performansi": performans,
            "cpr_odakli": cpr_odakli,
            "acil_durum": acil_durum,
            "kullanilan_esik": kullanilan_esik,
            "esik_tipi": esik_tipi,
            "yanit_suresi": yanit_suresi,
            "chunking_kullanildi": chunking_kullan,
            "chunking_istatistikleri": self.chunk_istatistikleri.copy(),
            "basari_orani": f"{(self.basarili_sorgu/max(1,self.toplam_sorgu))*100:.1f}%",
            "sonuc_detaylari": [
                (s['benzerlik_skoru'], s.get('ham_max_skor', 0), s.get('chunk_sayisi', 1), s['kategori'], s['guvenilirlik']) 
                for s in kaliteli_sonuclar[:3]
            ]
        }
    
    def _chunking_yanit_olustur(self, soru: str, sonuclar: List[Dict], acil: bool, chunking_kullan: bool) -> str:
        """Chunking-aware yanÄ±t ÅŸablonu"""
        if acil:
            header = "ğŸš¨ KRÄ°TÄ°K CPR PROTOKOLÃœ"
            uyari = "âš ï¸ **YAÅAMSAL ACÄ°L DURUM!** Bu protokolleri kesin takip edin.\n\n"
            renk = "ğŸ”´"
        else:
            header = "ğŸ“‹ CHUNKING-ENHANCEDCPRREHBERÄ°" if chunking_kullan else "ğŸ“‹ CPR REHBERÄ°"
            uyari = ""
            renk = "ğŸ”µ"
        
        yanit = f"## {header}\n\n{uyari}**Soru:** {soru}\n\n"
        
        if chunking_kullan:
            yanit += "ğŸ§© **Query Chunking Aktif:** Uzun sorgunuz parÃ§alara bÃ¶lÃ¼nerek analiz edildi.\n\n"
        
        for i, sonuc in enumerate(sonuclar):
            yanit += f"### {renk} Protokol {i+1}\n"
            yanit += f"**Kategori:** {sonuc['metadata']['kategori'].replace('_', ' ').title()}\n"
            yanit += f"**Alt Kategori:** {sonuc['metadata']['alt_kategori'].replace('_', ' ').title()}\n"
            yanit += f"**Ä°Ã§erik:** {sonuc['icerik']}\n\n"
            
            # Chunking detaylarÄ±
            if chunking_kullan and 'chunk_detaylari' in sonuc:
                yanit += f"**ğŸ§© Chunk Analizi:** {sonuc['chunk_sayisi']} parÃ§a, "
                if sonuc.get('multi_chunk_bonus', 1.0) > 1.0:
                    yanit += f"Multi-chunk bonus: +{((sonuc['multi_chunk_bonus']-1)*100):.0f}%"
                yanit += "\n"
            
            # Kalite gÃ¶stergeleri
            kalite_yildiz = "â­" * min(5, max(1, int(sonuc['benzerlik_skoru'] * 6)))
            yanit += f"**Kalite PuanÄ±:** {kalite_yildiz} ({sonuc['benzerlik_skoru']:.3f}) â€¢ "
            if chunking_kullan:
                yanit += f"**Max Chunk:** {sonuc.get('ham_max_skor', 0):.3f} â€¢ "
                yanit += f"**Avg Chunk:** {sonuc.get('ham_ortalama_skor', 0):.3f} â€¢ "
            yanit += f"**GÃ¼venilirlik:** %{sonuc['guvenilirlik']*100:.0f} â€¢ "
            yanit += f"**Kaynak:** {sonuc['metadata']['kaynak']}\n\n"
            yanit += "---\n\n"
        
        yanit += "### âš•ï¸ PROFESYONELLEÅTÄ°RÄ°LMÄ°Å UYARILAR\n"
        yanit += "â€¢ **AHA 2020 Guidelines** ve **ERC 2021** temelinde hazÄ±rlanmÄ±ÅŸtÄ±r\n"
        yanit += "â€¢ **GerÃ§ek uygulamada** mutlaka takÄ±m koordinasyonu yapÄ±n\n"
        yanit += "â€¢ **Acil durumlarda** 112'yi derhal arayÄ±n\n"
        if chunking_kullan:
            yanit += "â€¢ **Query Chunking** teknolojisi ile geliÅŸtirilmiÅŸ analiz\n"
        yanit += "â€¢ **SÃ¼rekli eÄŸitim** ve **dÃ¼zenli pratik** yapmayÄ± unutmayÄ±n\n"
        
        return yanit
    
    def _chunking_oneri_sistemi(self, soru: str, yakin_sonuclar: List[Dict], chunking_kullan: bool) -> str:
        """Chunking-aware akÄ±llÄ± Ã¶neri sistemi"""
        yanit = f"## ğŸ¯ AKILLI CPR REHBERÄ°\n\n"
        yanit += f"**Soru:** {soru}\n\n"
        yanit += "**Durum:** Spesifik protokol bulunamadÄ±"
        
        if chunking_kullan:
            yanit += ", query chunking kullanÄ±ldÄ± ancak yeterli eÅŸleÅŸme yok.\n\n"
        else:
            yanit += ".\n\n"
        
        # YakÄ±n sonuÃ§lar varsa gÃ¶ster
        if yakin_sonuclar:
            yanit += "### ğŸ“‹ YakÄ±n Konular:\n"
            for i, sonuc in enumerate(yakin_sonuclar):
                yanit += f"â€¢ **{sonuc['metadata']['kategori'].replace('_', ' ').title()}:** "
                yanit += f"{sonuc['icerik'][:80]}... (Skor: {sonuc['benzerlik_skoru']:.3f})\n"
            yanit += "\n"
        
        # Soru tipine gÃ¶re Ã¶zel Ã¶neriler
        if 'doz' in soru.lower() or 'miktar' in soru.lower():
            yanit += "### ğŸ’Š Ä°laÃ§ Dozu Rehberi:\n"
            yanit += "â€¢ **Epinefrin:** 1mg IV/IO her 3-5 dakikada bir\n"
            yanit += "â€¢ **Amiodarone:** Ä°lk doz 300mg IV, ikinci doz 150mg\n"
            yanit += "â€¢ **Atropin:** 1mg IV, maksimum 3mg (bradiasistol iÃ§in)\n"
            yanit += "â€¢ **Lidokain:** 1-1.5mg/kg IV (amiodarone alternatifi)\n\n"
        
        if any(kelime in soru.lower() for kelime in ['nasÄ±l', 'adÄ±m', 'prosedÃ¼r']):
            yanit += "### ğŸ“‹ ProsedÃ¼r Rehberi:\n"
            yanit += "â€¢ **CPR AdÄ±mlarÄ±:** YanÄ±tsÄ±zlÄ±k kontrolÃ¼ â†’ NabÄ±z kontrolÃ¼ â†’ 30:2 â†’ AED\n"
            yanit += "â€¢ **AED KullanÄ±mÄ±:** AÃ§ â†’ Elektrot yerleÅŸtir â†’ Analiz â†’ Åok (gerekirse)\n"
            yanit += "â€¢ **Hava Yolu:** Head-tilt chin-lift â†’ Bag-mask ventilasyon\n\n"
        
        yanit += "### ğŸ” GeliÅŸmiÅŸ Arama Ã–nerileri:\n"
        
        if not chunking_kullan:
            yanit += "â€¢ **Daha detaylÄ± sorular** sorun (sistem otomatik chunking yapacak)\n"
        else:
            yanit += "â€¢ **FarklÄ± kelimelerle** tekrar deneyin\n"
        
        yanit += "â€¢ **Spesifik terimler** kullanÄ±n (epinefrin, AED, kompresyon)\n"
        yanit += "â€¢ **YaÅŸ grubu** belirtin (yetiÅŸkin/Ã§ocuk/bebek)\n"
        yanit += "â€¢ **SayÄ±sal deÄŸerler** sorun (kaÃ§ mg, ne kadar, hangi oran)\n"
        yanit += "â€¢ **CPR kelimesi** ekleyin sorguya\n\n"
        
        yanit += "### ğŸ¯ PopÃ¼ler CPR SorularÄ±:\n"
        yanit += "- YetiÅŸkinlerde epinefrin dozu ve uygulama ÅŸekli nedir?\n"
        yanit += "- CPR kompresyon oranÄ± ve derinliÄŸi nasÄ±l olmalÄ±?\n"
        yanit += "- AED cihazÄ± nasÄ±l adÄ±m adÄ±m kullanÄ±lÄ±r?\n"
        yanit += "- Ã‡ocuklarda kalp masajÄ± nasÄ±l uygulanÄ±r?\n"
        yanit += "- Hipotermik arrest durumunda hangi protokol uygulanÄ±r?\n"
        
        return yanit
    
    def get_sistem_metrikleri(self):
        """Chunking-enhanced sistem metrikleri"""
        uptime = datetime.now() - self.sistem_baslatma_zamani if self.sistem_baslatma_zamani else None
        
        chunking_oran = f"{(self.chunking_kullanim_sayisi/max(1,self.toplam_sorgu))*100:.1f}%"
        
        return {
            'toplam_sorgu': self.toplam_sorgu,
            'basarili_sorgu': self.basarili_sorgu,
            'basari_orani': f"{(self.basarili_sorgu/max(1,self.toplam_sorgu))*100:.1f}%",
            'ortalama_yanit_suresi': f"{sum(self.ortalama_yanit_suresi)/max(1,len(self.ortalama_yanit_suresi)):.2f}s",
            'uptime': str(uptime).split('.')[0] if uptime else "0:00:00",
            'kategori_dagilimi': self.kategori_dagilimi,
            'database_boyutu': self.retriever.koleksiyon.count() if self.retriever.koleksiyon else 0,
            'chunking_kullanim_sayisi': self.chunking_kullanim_sayisi,
            'chunking_oran': chunking_oran,
            'chunk_istatistikleri': self.chunk_istatistikleri
        }

# ğŸ¨ MODERN UI + OKUNAKLIK DÃœZELTMELERÄ°
st.set_page_config(
    page_title="CPR Chunking System ğŸ§©",
    page_icon="ğŸ«€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ğŸ”§ UI OKUNAKLIK DÃœZELTMELERÄ° - BEYAZLARDAKÄ° SIYAH METÄ°N
st.markdown("""
<style>
    /* Ana tema */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(102, 126, 234, 0.3);
    }
    
    /* ğŸ”§ BEYAZ KARTLARDA SÄ°YAH METÄ°N - OKUNAKLIK DÃœZELTMESÄ° */
    .metric-card {
        background: linear-gradient(145deg, #f8f9fa, #e9ecef);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #667eea;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
        transition: transform 0.3s ease;
        color: #212529 !important; /* SÄ°YAH METÄ°N */
    }
    
    .metric-card h4, .metric-card p, .metric-card li, .metric-card strong {
        color: #212529 !important; /* TÃœM METÄ°NLER SÄ°YAH */
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.15);
    }
    
    /* ğŸ”§ BAÅARI KARTINDA KOYU YEÅÄ°L METÄ°N */
    .success-card {
        background: linear-gradient(145deg, #d4edda, #c3e6cb);
        border: 1px solid #c3e6cb;
        border-radius: 12px;
        padding: 1rem;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(40, 167, 69, 0.2);
        color: #155724 !important; /* KOYU YEÅÄ°L */
    }
    
    .success-card strong {
        color: #0f4229 !important; /* DAHA KOYU YEÅÄ°L */
    }
    
    /* ğŸ”§ UYARI KARTINDA KOYU SARI METÄ°N */
    .warning-card {
        background: linear-gradient(145deg, #fff3cd, #ffeaa7);
        border: 1px solid #ffeaa7;
        border-radius: 12px;
        padding: 1rem;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(255, 193, 7, 0.2);
        color: #856404 !important; /* KOYU SARI */
    }
    
    .warning-card strong {
        color: #664d03 !important; /* DAHA KOYU SARI */
    }
    
    /* ğŸ”§ ACÄ°L KART KOYU KIRMIZI METÄ°N */
    .emergency-card {
        background: linear-gradient(145deg, #f8d7da, #f1aeb5);
        border: 1px solid #f1aeb5;
        border-radius: 12px;
        padding: 1rem;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(220, 53, 69, 0.2);
        animation: pulse 2s infinite;
        color: #721c24 !important; /* KOYU KIRMIZI */
    }
    
    .emergency-card strong {
        color: #491217 !important; /* DAHA KOYU KIRMIZI */
    }
    
    @keyframes pulse {
        0% { box-shadow: 0 4px 15px rgba(220, 53, 69, 0.2); }
        50% { box-shadow: 0 6px 25px rgba(220, 53, 69, 0.4); }
        100% { box-shadow: 0 4px 15px rgba(220, 53, 69, 0.2); }
    }
    
    /* ğŸ”§ CHUNKING Ã–ZEL KARTI */
    .chunking-card {
        background: linear-gradient(145deg, #e3f2fd, #bbdefb);
        border: 1px solid #90caf9;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(33, 150, 243, 0.2);
        color: #0d47a1 !important; /* KOYU MAVÄ° */
    }
    
    .chunking-card strong, .chunking-card h4 {
        color: #0d47a1 !important;
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Button styling */
    .stButton > button {
        background: linear-gradient(145deg, #667eea, #764ba2);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* ğŸ”§ DATAFRAME OKUNAKLIK DÃœZELTMESÄ° */
    .stDataFrame {
        background-color: white !important;
    }
    
    .stDataFrame table {
        color: #212529 !important; /* SÄ°YAH METÄ°N */
    }
    
    .stDataFrame th {
        background-color: #f8f9fa !important;
        color: #495057 !important; /* KOYU GRÄ° BAÅLIK */
        font-weight: bold !important;
    }
    
    .stDataFrame td {
        color: #212529 !important; /* SÄ°YAH HÃœCRE METNÄ° */
    }
    
    /* Input styling */
    .stTextInput > div > div > input {
        border: 2px solid #e9ecef;
        border-radius: 8px;
        padding: 0.75rem;
        font-size: 1rem;
        transition: border-color 0.3s ease;
        color: #212529 !important; /* SÄ°YAH INPUT METNÄ° */
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
</style>
""", unsafe_allow_html=True)

# Ana baÅŸlÄ±k
st.markdown("""
<div class="main-header">
    <h1>ğŸ§© CPR Query Chunking System v2.1</h1>
    <p><strong>Uzun Sorgu DesteÄŸi â€¢ AkÄ±llÄ± ParÃ§alama â€¢ GeliÅŸmiÅŸ UI</strong></p>
</div>
""", unsafe_allow_html=True)

# GeliÅŸmiÅŸ Ã¶rnek sorular
chunking_ornekleri = [
    "YetiÅŸkinlerde kardiyak arrest durumunda epinefrin dozu ve uygulama ÅŸekli nedir?",
    "CPR sÄ±rasÄ±nda kompresyon oranÄ±, derinliÄŸi ve hÄ±zÄ± nasÄ±l olmalÄ±dÄ±r?",
    "AED kullanÄ±mÄ±nda dikkat edilmesi gereken adÄ±mlar ve gÃ¼venlik Ã¶nlemleri nelerdir?",
    "Ã‡ocuklarda kalp masajÄ± tekniÄŸi, kompresyon derinliÄŸi ve ventilasyon oranÄ± nasÄ±ldÄ±r?",
    "Hipotermik arrest durumunda uygulanan Ã¶zel protokoller ve dikkat edilecek hususlar?",
    "Hamile hastalarda CPR uygulamasÄ± ve Ã¶zel pozisyonlama teknikleri nelerdir?",
    "CPR sÄ±rasÄ±nda yapÄ±lan yapay solunum ile ilgili enfeksiyon riskleri ve korunma yÃ¶ntemleri",
    "Ä°leri yaÅŸam desteÄŸinde kullanÄ±lan ilaÃ§larÄ±n dozlarÄ± ve uygulama zamanlarÄ±"
]

# SIDEBAR - CHUNKING Ã–ZELLÄ°KLERÄ°YLE
with st.sidebar:
    st.markdown("## ğŸ§© CPR Chunking Hub")
    st.markdown("---")
    
    # Chunking bilgisi
    st.markdown("""
    <div class="chunking-card">
        <h4>ğŸ§© Query Chunking Nedir?</h4>
        <p><strong>Uzun sorularÄ±nÄ±zÄ±</strong> otomatik olarak parÃ§alara bÃ¶ler ve her parÃ§a iÃ§in ayrÄ± arama yapar. SonuÃ§larÄ± birleÅŸtirerek <strong>daha doÄŸru yanÄ±tlar</strong> verir.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # HÄ±zlÄ± eriÅŸim butonlarÄ±
    st.markdown("### ğŸš€ Chunking Test SorularÄ±")
    for i, soru in enumerate(chunking_ornekleri):
        kisa_soru = soru[:35] + "..." if len(soru) > 35 else soru
        if st.button(kisa_soru, key=f"chunk_btn_{i}", width='stretch'):
            st.session_state.chunk_soru_input = soru
    
    st.markdown("---")
    
    # Sistem durumu
    st.markdown("### âš™ï¸ Sistem Durumu")
    
    if CHROMA_AVAILABLE and TRANSFORMERS_AVAILABLE:
        st.success("âœ… Chunking System Aktif")
        st.info("ğŸ§  Model: distiluse-multilingual")
        st.info("ğŸ§© Chunking: AkÄ±llÄ± ParÃ§alama")
        st.info("ğŸ¯ EÅŸik: Dinamik")
    else:
        st.error("âŒ KÃ¼tÃ¼phaneler Eksik")
        st.code("pip install chromadb sentence-transformers plotly")
    
    st.markdown("---")
    
    # Chunking Ã¶zellikler
    st.markdown("### ğŸ† Chunking Ã–zellikleri")
    st.markdown("""
    â€¢ ğŸ§© **Otomatik Chunking** (8+ kelime)
    â€¢ ğŸ¯ **Multi-Chunk Bonus**
    â€¢ ğŸ“Š **Dinamik EÅŸikler**
    â€¢ ğŸ” **Mega Kelime GeniÅŸletme**
    â€¢ âš¡ **Parallel Processing**
    â€¢ ğŸ“ˆ **Chunk Ä°statistikleri**
    â€¢ ğŸ¨ **Enhanced UI/UX**
    â€¢ ğŸ”§ **Okunabilirlik Fix**
    """)

# Sistem baÅŸlatma
if "chunk_sistem" not in st.session_state:
    with st.spinner("ğŸ§© Query Chunking sistemi baÅŸlatÄ±lÄ±yor..."):
        st.session_state.chunk_sistem = ChunkingCPRSistemi()
        st.session_state.chunk_basladi = st.session_state.chunk_sistem.sistem_baslat()

# Ana iÃ§erik
if not st.session_state.chunk_basladi:
    st.markdown("""
    <div class="warning-card">
        <h3>âŒ Chunking Sistemi BaÅŸlatÄ±lamadÄ±</h3>
        <p><strong>Kontrol listesi:</strong></p>
        <ul>
            <li><strong>cpr_egitim_bilgi_bankasi.json</strong> dosyasÄ± var mÄ±?</li>
            <li>KÃ¼tÃ¼phaneler kurulu mu? <code>pip install chromadb sentence-transformers plotly</code></li>
            <li>Ä°nternet baÄŸlantÄ±sÄ± aktif mi? (Model indirme)</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
else:
    st.markdown('<div class="success-card">ğŸ§© <strong>Query Chunking sistemi aktif!</strong> Uzun sorularÄ±nÄ±z otomatik parÃ§alanacak.</div>', unsafe_allow_html=True)
    
    # CHUNKING METRÄ°KLERÄ° DASHBOARD
    metrikliler = st.session_state.chunk_sistem.get_sistem_metrikleri()
    
    st.markdown("## ğŸ“Š Chunking Dashboard")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ§© Toplam Sorgu",
            value=metrikliler['toplam_sorgu'],
            delta=f"Chunking: {metrikliler['chunking_kullanim_sayisi']}"
        )
        
    with col2:
        st.metric(
            label="ğŸ“ˆ BaÅŸarÄ± OranÄ±",
            value=metrikliler['basari_orani'],
            delta=f"Chunking OranÄ±: {metrikliler['chunking_oran']}"
        )
    
    with col3:
        st.metric(
            label="âš¡ Ortalama YanÄ±t",
            value=metrikliler['ortalama_yanit_suresi'],
            delta="Enhanced Speed"
        )
    
    with col4:
        chunk_stats = metrikliler['chunk_istatistikleri']
        ortalama_chunk = f"{chunk_stats['ortalama_chunk_per_sorgu']:.1f}"
        st.metric(
            label="ğŸ§© Avg Chunk/Query",
            value=ortalama_chunk,
            delta=f"Toplam: {chunk_stats['toplam_chunk']}"
        )
    
    # Chunking performans detaylarÄ±
    if metrikliler['chunking_kullanim_sayisi'] > 0:
        st.markdown("---")
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Chunking vs Normal karÅŸÄ±laÅŸtÄ±rma grafiÄŸi
            chunking_data = {
                'Tip': ['Normal Sorgu', 'Chunking Sorgu'],
                'SayÄ±': [metrikliler['toplam_sorgu'] - metrikliler['chunking_kullanim_sayisi'], 
                        metrikliler['chunking_kullanim_sayisi']],
                'Renk': ['#ffa500', '#667eea']
            }
            
            fig = px.bar(
                x=chunking_data['Tip'],
                y=chunking_data['SayÄ±'],
                color=chunking_data['Tip'],
                title="ğŸ“Š Chunking vs Normal Sorgu DaÄŸÄ±lÄ±mÄ±",
                color_discrete_map={
                    'Normal Sorgu': '#ffa500',
                    'Chunking Sorgu': '#667eea'
                }
            )
            fig.update_layout(showlegend=False, template="plotly_white")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("### ğŸ§© Chunking Ä°statistikleri")
            chunk_stats = metrikliler['chunk_istatistikleri']
            
            st.markdown(f"""
            <div class="metric-card">
                <strong>ğŸ“Š Toplam Chunk:</strong> {chunk_stats['toplam_chunk']}<br>
                <strong>âœ… BaÅŸarÄ±lÄ± Chunk:</strong> {chunk_stats['basarili_chunk']}<br>
                <strong>ğŸ“ˆ Ortalama/Sorgu:</strong> {chunk_stats['ortalama_chunk_per_sorgu']:.1f}<br>
                <strong>ğŸ¯ Chunking OranÄ±:</strong> {metrikliler['chunking_oran']}
            </div>
            """, unsafe_allow_html=True)
    
    # Kategori daÄŸÄ±lÄ±mÄ± (dÃ¼zeltilmiÅŸ renk)
    if metrikliler['kategori_dagilimi']:
        st.markdown("---")
        st.markdown("### ğŸ“‚ CPR Kategori DaÄŸÄ±lÄ±mÄ±")
        
        fig = px.pie(
            values=list(metrikliler['kategori_dagilimi'].values()),
            names=[k.replace('_', ' ').title() for k in metrikliler['kategori_dagilimi'].keys()],
            title="CPR DokÃ¼man Kategorileri",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig.update_traces(textfont_color="black")  # ğŸ”§ SÄ°YAH METÄ°N
        fig.update_layout(template="plotly_white")
        st.plotly_chart(fig, use_container_width=True)
    
    # Performans trend grafiÄŸi
    performans_data = st.session_state.chunk_sistem.retriever.get_performans_grafigi()
    if performans_data:
        st.markdown("---")
        st.markdown("### ğŸ“ˆ Chunking Performans Trendi")
        
        fig = go.Figure()
        
        # Skor Ã§izgisi
        fig.add_trace(go.Scatter(
            x=list(range(len(performans_data['skorlar']))),
            y=performans_data['skorlar'],
            mode='lines+markers',
            name='Benzerlik Skoru',
            line=dict(color='#667eea', width=3),
            marker=dict(size=8, color='#764ba2'),
            hovertemplate='<b>%{text}</b><br>Skor: %{y:.3f}<br>Chunk: %{customdata}<extra></extra>',
            text=performans_data['sorgular'],
            customdata=performans_data['chunk_sayilari']
        ))
        
        # Chunk sayÄ±sÄ± bar
        fig.add_trace(go.Bar(
            x=list(range(len(performans_data['chunk_sayilari']))),
            y=performans_data['chunk_sayilari'],
            name='Chunk SayÄ±sÄ±',
            yaxis='y2',
            marker_color='rgba(255, 165, 0, 0.6)',
            hovertemplate='<b>%{text}</b><br>Chunk: %{y}<extra></extra>',
            text=performans_data['sorgular']
        ))
        
        fig.update_layout(
            title="Son SorgularÄ±n Performans ve Chunk Analizi",
            xaxis_title="Sorgu SÄ±rasÄ±",
            yaxis_title="Benzerlik Skoru",
            yaxis2=dict(
                title="Chunk SayÄ±sÄ±",
                overlaying='y',
                side='right',
                range=[0, max(performans_data['chunk_sayilari']) + 1]
            ),
            template="plotly_white",
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # CHUNKING SORGU BÃ–LÃœMÃœ
    st.markdown("## ğŸ’¬ AkÄ±llÄ± Chunking Sorgulama")
    
    # Chunking aÃ§Ä±klama kutusu
    st.markdown("""
    <div class="chunking-card">
        <h4>ğŸ§© NasÄ±l Ã‡alÄ±ÅŸÄ±r?</h4>
        <p><strong>8+ kelimelik sorular</strong> otomatik olarak parÃ§alara bÃ¶lÃ¼nÃ¼r. Ã–rneÄŸin:</p>
        <p><em>"AED kullanÄ±mÄ±nda dikkat edilmesi gereken adÄ±mlar ve gÃ¼venlik Ã¶nlemleri"</em></p>
        <p>â†“</p>
        <p><strong>Chunk 1:</strong> "AED kullanÄ±mÄ±nda dikkat edilmesi gereken"<br>
        <strong>Chunk 2:</strong> "adÄ±mlar ve gÃ¼venlik Ã¶nlemleri"<br>
        <strong>Chunk 3:</strong> "CPR AED kullanÄ±mÄ±" (otomatik eklenen)</p>
    </div>
    """, unsafe_allow_html=True)
    
    soru = st.text_input(
        "CPR konusunda uzun ve detaylÄ± sorunuzu yazÄ±n:",
        value=st.session_state.get('chunk_soru_input', ''),
        placeholder="Ã–rn: YetiÅŸkinlerde kardiyak arrest durumunda epinefrin dozÄ±, uygulama ÅŸekli ve dikkat edilmesi gereken yan etkiler nelerdir?",
        key="chunk_ana_input",
        help="ğŸ’¡ Ä°pucu: 8+ kelimelik sorular otomatik chunking alÄ±r"
    )
    
    # Chunking preview
    if soru.strip():
        kelime_sayisi = len(soru.split())
        if kelime_sayisi > 8:
            st.markdown(f"""
            <div style="background: linear-gradient(145deg, #e8f5e8, #d4f1d4); padding: 1rem; border-radius: 8px; margin: 1rem 0; color: #2e7d32;">
                <strong>ğŸ§© Chunking Aktif:</strong> {kelime_sayisi} kelimelik sorgu parÃ§alara bÃ¶lÃ¼necek
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div style="background: linear-gradient(145deg, #fff3e0, #ffecb3); padding: 1rem; border-radius: 8px; margin: 1rem 0; color: #f57f17;">
                <strong>ğŸ“ Normal Arama:</strong> {kelime_sayisi} kelimelik sorgu iÃ§in chunking kullanÄ±lmayacak
            </div>
            """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([3, 1, 1])
    
    with col1:
        sorgula_btn = st.button("ğŸ§© Chunking Analizi", type="primary", width='stretch')
    
    with col2:
        if st.button("ğŸ”„ Temizle", width='stretch'):
            st.session_state.chunk_soru_input = ""
            st.rerun()
    
    with col3:
        if st.button("ğŸ² Rastgele Uzun", width='stretch'):
            st.session_state.chunk_soru_input = random.choice(chunking_ornekleri)
            st.rerun()
    
    # CHUNKING SONUÃ‡LARI
    if sorgula_btn and soru.strip():
        with st.spinner("ğŸ§© AkÄ±llÄ± chunking sistemi analiz yapÄ±yor..."):
            time.sleep(0.8)  # Professional feel
            sonuc = st.session_state.chunk_sistem.chunking_sorgulama(soru)
        
        st.markdown("---")
        
        # Chunking durumu kartÄ±
        if sonuc["chunking_kullanildi"]:
            st.markdown('<div class="chunking-card">ğŸ§© <strong>Query Chunking KullanÄ±ldÄ±!</strong> Uzun sorgunuz parÃ§alara bÃ¶lÃ¼ndÃ¼ ve analiz edildi.</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div style="background: linear-gradient(145deg, #f3e5f5, #e1bee7); padding: 1rem; border-radius: 12px; margin: 1rem 0; color: #4a148c;">ğŸ“ <strong>Normal Arama:</strong> KÄ±sa sorgu iÃ§in chunking kullanÄ±lmadÄ±.</div>', unsafe_allow_html=True)
        
        # SonuÃ§ durumu kartÄ±
        if sonuc["basarili"]:
            if sonuc["acil_durum"]:
                st.markdown('<div class="emergency-card">ğŸš¨ <strong>KRÄ°TÄ°K ACÄ°L PROTOKOL BULUNDU!</strong> YaÅŸamsal Ã¶neme sahip bilgi.</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="success-card">âœ… <strong>Chunking baÅŸarÄ±lÄ±!</strong> YÃ¼ksek kaliteli protokol sonuÃ§larÄ± bulundu.</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="warning-card">âš ï¸ <strong>Chunking tamamlandÄ± ancak yeterli eÅŸleÅŸme bulunamadÄ±.</strong> AkÄ±llÄ± Ã¶neriler sunuluyor.</div>', unsafe_allow_html=True)
        
        # Ana yanÄ±t
        st.markdown(sonuc['yanit'])
        
        # CHUNKING ANALÄ°Z RAPORU
        st.markdown("---")
        st.markdown("## ğŸ“Š Chunking Analiz Raporu")
        
        # ÃœÃ§ sÃ¼tunlu analiz
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("### ğŸ” Arama DetaylarÄ±")
            st.markdown(f"""
            <div class="metric-card">
                <strong>ğŸ¯ En Ä°yi Skor:</strong> {sonuc['en_iyi_skor']:.3f}<br>
                <strong>ğŸ” Bulunan DokÃ¼man:</strong> {sonuc['bulunan_dokuman_sayisi']}<br>
                <strong>â­ Kaliteli SonuÃ§:</strong> {sonuc['kaliteli_sonuc_sayisi']}<br>
                <strong>ğŸšï¸ KullanÄ±lan EÅŸik:</strong> {sonuc['kullanilan_esik']:.3f}<br>
                <strong>ğŸ“ EÅŸik Tipi:</strong> {sonuc['esik_tipi'].title()}
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("### ğŸ§© Chunking Ä°statistikleri")
            chunk_stats = sonuc['chunking_istatistikleri']
            st.markdown(f"""
            <div class="metric-card">
                <strong>ğŸ§© Chunking KullanÄ±ldÄ±:</strong> {'âœ… Evet' if sonuc['chunking_kullanildi'] else 'âŒ HayÄ±r'}<br>
                <strong>âš¡ YanÄ±t SÃ¼resi:</strong> {sonuc['yanit_suresi']:.2f}s<br>
                <strong>ğŸ“Š Toplam Chunk:</strong> {chunk_stats['toplam_chunk']}<br>
                <strong>ğŸ“ˆ Avg Chunk/Q:</strong> {chunk_stats['ortalama_chunk_per_sorgu']:.1f}<br>
                <strong>âœ… BaÅŸarÄ±lÄ± Chunk:</strong> {chunk_stats['basarili_chunk']}
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("### ğŸ“ˆ Sistem PerformansÄ±")
            st.markdown(f"""
            <div class="metric-card">
                <strong>ğŸ† Performans:</strong> {sonuc['sistem_performansi']}<br>
                <strong>ğŸ“Š Genel BaÅŸarÄ±:</strong> {sonuc['basari_orani']}<br>
                <strong>ğŸ«€ CPR OdaklÄ±:</strong> {'âœ… Evet' if sonuc['cpr_odakli'] else 'âŒ HayÄ±r'}<br>
                <strong>ğŸš¨ Acil Durum:</strong> {'ğŸ”´ EVET' if sonuc['acil_durum'] else 'ğŸŸ¢ Normal'}<br>
                <strong>ğŸ¯ Sorgu KarmaÅŸÄ±klÄ±ÄŸÄ±:</strong> {'YÃ¼ksek' if sonuc['chunking_kullanildi'] else 'Basit'}
            </div>
            """, unsafe_allow_html=True)
        
        # DetaylÄ± eÅŸleÅŸme tablosu - ğŸ”§ OKUNAKLIK DÃœZELTÄ°LMÄ°Å
        if sonuc["sonuc_detaylari"]:
            st.markdown("---")
            st.markdown("### ğŸ¯ En Ä°yi EÅŸleÅŸmeler - Chunking Detay Analizi")
            
            tablo_data = []
            for i, (final_skor, ham_max_skor, chunk_sayisi, kategori, guvenilirlik) in enumerate(sonuc["sonuc_detaylari"]):
                # Chunking bonus hesapla
                if chunk_sayisi > 1:
                    multi_bonus = f"+{((chunk_sayisi-1)*15):.0f}%"
                else:
                    multi_bonus = "Yok"
                
                # Kalite deÄŸerlendirmesi
                if final_skor > 0.7:
                    kalite = "ğŸ† MÃ¼kemmel"
                    renk = "ğŸŸ¢"
                elif final_skor > 0.5:
                    kalite = "ğŸš€ Ã‡ok Ä°yi"
                    renk = "ğŸ”µ"
                elif final_skor > 0.3:
                    kalite = "ğŸ“ˆ Ä°yi"
                    renk = "ğŸŸ¡"
                else:
                    kalite = "ğŸ“Š Orta"
                    renk = "ğŸŸ "
                
                tablo_data.append({
                    "ğŸ”": f"#{i+1}",
                    "Durum": renk,
                    "ğŸ† Final Skor": f"{final_skor:.3f}",
                    "ğŸ“Š Ham Skor": f"{ham_max_skor:.3f}",
                    "ğŸ§© Chunk SayÄ±sÄ±": chunk_sayisi,
                    "ğŸ Multi Bonus": multi_bonus,
                    "ğŸ“‚ Kategori": kategori.replace('_', ' ').title(),
                    "â­ GÃ¼venilirlik": f"%{guvenilirlik*100:.0f}",
                    "ğŸ¯ Kalite": kalite
                })
            
            # Okunabilirlik dÃ¼zeltilmiÅŸ tablo
            st.dataframe(
                tablo_data, 
                use_container_width=True, 
                hide_index=True,
                column_config={
                    "ğŸ”": st.column_config.TextColumn(width="small"),
                    "Durum": st.column_config.TextColumn(width="small"),
                    "ğŸ† Final Skor": st.column_config.NumberColumn(format="%.3f"),
                    "ğŸ“Š Ham Skor": st.column_config.NumberColumn(format="%.3f"),
                    "ğŸ§© Chunk SayÄ±sÄ±": st.column_config.NumberColumn(format="%d")
                }
            )
    
    elif sorgula_btn and not soru.strip():
        st.markdown('<div class="warning-card">â— <strong>LÃ¼tfen bir CPR sorusu yazÄ±n.</strong> Uzun sorular iÃ§in chunking Ã¶zelliÄŸi kullanÄ±lacak.</div>', unsafe_allow_html=True)

# FOOTER - CHUNKING Ã–ZELLÄ°KLÄ°
st.markdown("---")
st.markdown("## ğŸ“ CPR Chunking Teknoloji Merkezi")

# Ã–zellik showcase
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    <div class="metric-card">
        <h4>ğŸ§© Query Chunking Teknolojisi</h4>
        <ul>
            <li><strong>Otomatik sorgu parÃ§alama</strong></li>
            <li><strong>Multi-chunk bonus sistemi</strong></li>
            <li><strong>Parallel processing</strong></li>
            <li><strong>Intelligent chunk weighting</strong></li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div class="metric-card">
        <h4>ğŸ¯ GeliÅŸmiÅŸ Arama Sistemi</h4>
        <ul>
            <li><strong>Dinamik eÅŸik deÄŸerleri</strong></li>
            <li><strong>Mega kelime geniÅŸletme</strong></li>
            <li><strong>Context-aware scoring</strong></li>
            <li><strong>Real-time chunk analysis</strong></li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

with col3:
    st.markdown("""
    <div class="metric-card">
        <h4>ğŸ“Š Performans & UI Ä°yileÅŸtirmeleri</h4>
        <ul>
            <li><strong>Okunabilirlik dÃ¼zeltmeleri</strong></li>
            <li><strong>Chunk performans grafikleri</strong></li>
            <li><strong>Enhanced color contrast</strong></li>
            <li><strong>Professional dashboard</strong></li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# Final professional card
st.markdown("""
<div style="text-align: center; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 3rem; border-radius: 20px; color: white; margin: 2rem 0; box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);">
    <h2>ğŸ§© CPR Query Chunking System v2.1</h2>
    <p style="font-size: 1.2em; margin: 1rem 0;"><strong>Uzun sorularÄ±nÄ±zÄ± parÃ§alara bÃ¶len akÄ±llÄ± teknoloji</strong></p>
    <div style="display: flex; justify-content: center; gap: 2rem; margin-top: 1.5rem; flex-wrap: wrap;">
        <div>ğŸ§© <strong>Auto Chunking</strong></div>
        <div>ğŸ¯ <strong>Multi-Chunk Bonus</strong></div>
        <div>ğŸ“Š <strong>Dynamic Thresholds</strong></div>
        <div>âš¡ <strong>Enhanced Speed</strong></div>
        <div>ğŸ”§ <strong>UI Fixed</strong></div>
    </div>
</div>
""", unsafe_allow_html=True)

st.markdown("""
<div style="text-align: center; padding: 1rem; background: rgba(102, 126, 234, 0.1); border-radius: 10px; margin: 1rem 0; color: #212529;">
    <p><strong>âš ï¸ UYARI:</strong> Bu sistem eÄŸitim amaÃ§lÄ±dÄ±r. GerÃ§ek acil durumlarda <strong>112</strong>'yi arayÄ±n ve profesyonel tÄ±bbi yardÄ±m alÄ±n.</p>
    <p>Query Chunking teknolojisi ile <strong>uzun ve karmaÅŸÄ±k sorularÄ±nÄ±z</strong> daha doÄŸru yanÄ±tlanÄ±r.</p>
</div>
""", unsafe_allow_html=True)